# -*- coding: utf-8 -*-
"""pydp-27_PETROV_I_A_DIPLOMA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UcO5zoYUYUPhwVnSflP7IE7AduO86qQY

#Петров Игорь (pydp-27)

##Задание к дипломной работе по курсу "Python для анализа данных"

###1 Загрузка DF
"""

#1 Загрузите файл HR.csv в pandas dataframe
import pandas as pd
import numpy as np

df = pd.read_csv('HR.csv')#,';')

df.head()

"""###2 Метрики статистики"""

#2 Рассчитайте основные статистики для переменных(среднее,медиана,мода,мин/макс,сред.отклонение).

print(round(df.describe(),3))

print('Метрики по числовым атрибутам:\n Атрибут\tСреднее\tМедиана\tМин\tМакс\tСКО\tМода\n')
slAVG = round(df['satisfaction_level'].mean(), 2)
slMed = round(df['satisfaction_level'].median() , 2)
slMin = round(df['satisfaction_level'].min(), 2)
slMax = round(df['satisfaction_level'].max(), 2)
slSko = round(df['satisfaction_level'].std(), 2)
slModa = round(df['satisfaction_level'].mode()[0], 2)

print('satisfaction_level:',slAVG,slMed,slMin,slMax, slSko, slModa)

leAVG = round(df['last_evaluation'].mean(), 2)
leMed = round(df['last_evaluation'].median() , 2)
leMin = round(df['last_evaluation'].min(), 2)
leMax = round(df['last_evaluation'].max(), 2)
leSko = round(df['last_evaluation'].std(), 2)
leModa = round(df['last_evaluation'].mode()[0], 2)

print('last_evaluation:',leAVG,leMed,leMin,leMax, leSko, leModa)

npAVG = round(df['number_project'].mean(), 2)
npMed = round(df['number_project'].median() , 2)
npMin = round(df['number_project'].min(), 2)
npMax = round(df['number_project'].max(), 2)
npSko = round(df['number_project'].std(), 2)
npModa = round(df['number_project'].mode()[0], 2)

print('number_project:',npAVG,npMed,npMin,npMax, npSko, npModa)

amhAVG = round(df['average_montly_hours'].mean(), 2)
amhMed = round(df['average_montly_hours'].median() , 2)
amhMin = round(df['average_montly_hours'].min(), 2)
amhMax = round(df['average_montly_hours'].max(), 2)
amhSko = round(df['average_montly_hours'].std(), 2)
amhModa = round(df['average_montly_hours'].mode()[0], 2)

print('average_montly_hours:',amhAVG,amhMed,amhMin,amhMax, amhSko, amhModa)

tscAVG = round(df['time_spend_company'].mean(), 2)
tscMed = round(df['time_spend_company'].median() , 2)
tscMin = round(df['time_spend_company'].min(), 2)
tscMax = round(df['time_spend_company'].max(), 2)
tscSko = round(df['time_spend_company'].std(), 2)
tscModa = round(df['time_spend_company'].mode()[0], 2)

print('time_spend_company:',tscAVG,tscMed,tscMin,tscMax, tscSko, tscModa)

waAVG = round(df['Work_accident'].mean(), 2)
waMed = round(df['Work_accident'].median() , 2)
waMin = round(df['Work_accident'].min(), 2)
waMax = round(df['Work_accident'].max(), 2)
waSko = round(df['Work_accident'].std(), 2)
waModa = round(df['Work_accident'].mode()[0], 2)

print('Work_accident:',waAVG,waMed,waMin,waMax, waSko, waModa)

lAVG = round(df['left'].mean(), 2)
lMed = round(df['left'].median() , 2)
lMin = round(df['left'].min(), 2)
lMax = round(df['left'].max(), 2)
lSko = round(df['left'].std(), 2)
lModa = round(df['left'].mode()[0], 2)

print('left:',lAVG,lMed,lMin,lMax, lSko, lModa)

pl5AVG = round(df['promotion_last_5years'].mean(), 2)
pl5Med = round(df['promotion_last_5years'].median() , 2)
pl5Min = round(df['promotion_last_5years'].min(), 2)
pl5Max = round(df['promotion_last_5years'].max(), 2)
pl5Sko = round(df['promotion_last_5years'].std(), 2)
pl5Moda = round(df['promotion_last_5years'].mode()[0], 2)

print('promotion_last_5years:',pl5AVG,pl5Med,pl5Min,pl5Max, pl5Sko, pl5Moda)

"""###3 Кор матрица колич перем"""

#3 Рассчитайте и визуализировать корреляционную матрицу для количественных переменных. 
  #Определите две самые скоррелированные и две наименее скоррелированные переменные.
df.corr()

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.heatmap(df.corr(), annot=True, cbar=True, cmap = "inferno")

print('Наиболее коррелируют:\n 1) last_evaluation - number_project \n 2) number_project - average_montly_hours')
print('Наименее коррелируют:\n 1) satisfaction_level - left \n 2) Work_accident - left')

print("Графики наибольшей корреляции:")

df.plot(kind='hist', 
        x='number_project', 
        y='last_evaluation', 
        cmap='summer',
        xlabel = 'number_project',
        ylabel = 'last_evaluation',
        title='Корреляция: Время последней оценки(годы) - Кол-во проектов')
plt.show()

df.plot(kind='hist', 
        x='number_project', 
        y='average_montly_hours', 
        cmap='summer',
        xlabel = 'number_project',
        ylabel = 'average_montly_hours',
        title='Корреляция: Среднее кол-во часов раб. времени(месяц) - Кол-во проектов')

plt.show()

print("Графики наименьшей корреляции:")

df.plot(kind='kde', 
        x='left', 
        y='satisfaction_level', 
        cmap='winter',
        xlabel = 'left',
        ylabel = 'satisfaction_level',
        title='Корреляция: Уровень удовл. работой - Уволенный сотрудник')

plt.show()

df.plot(kind='kde', 
        x='left', 
        y='Work_accident',
        cmap='winter',
        xlabel = 'left',
        ylabel = 'Work_accident',
        title='Корреляция: Несч. случаи на раб. месте - Уволенный сотрудник')

plt.show()

"""###4 Кол-во сотр/ДЕП"""

#4 Рассчитайте сколько сотрудников работает в каждом департаменте.
emplWorkDep = df[df['left'] == 0]
emplLeftDep = df[df['left'] == 1]

emplWorkDep=  emplWorkDep[['department','salary']].groupby('department').count()
emplLeftDep = emplLeftDep[['department','salary']].groupby('department').count()

emplWorkDep.rename(columns={'salary':'employes'}, inplace=True)
emplLeftDep.rename(columns={'salary':'employes'}, inplace=True)

unionDF = emplWorkDep.merge(emplLeftDep, how='inner', on='department', suffixes=('_work', '_left'))

print('Сотрудники по департаменту:\n', unionDF)

unionDF.plot(kind='bar', rot=90,
             title='Работающие/уволенные сотрудники по депаратментам',
             xlabel = 'Департамент',
             ylabel = 'Кол-во сотрудников')

"""###5 Расп сотр по ЗП"""

#5 Показать распределение сотрудников по зарплатам.
cntEmplSlr = df[['salary', 'department', 'left']].groupby(['salary','left']).count().fillna(0)

cntEmplSlr.rename(columns={'department':'count'}, inplace=True)

print('Распределение зарплат по всем сотрудникам (в т.ч. уволенным):\n', cntEmplSlr)

cntEmplSlr.plot(kind='line', rot=90,
             title='Грейд ЗП по сотрудникам',
             xlabel = 'Грейд ЗП (Уволенные/Работающие)',
             ylabel = 'Кол-во сотрудников')

"""###6 Распр сотр по зп/деп"""

#6 Показать распределение сотрудников по зарплатам в каждом департаменте по отдельности
emplSalDep = df[['department', 'salary', 'left']].pivot_table(
                        index='department', 
                        columns='salary',
                        values='salary', 
                        aggfunc= 'count').fillna(0)

print('Распределение зарплат сотрудников в департаментах (в т.ч. уволенным):\n', emplSalDep)
sns.heatmap(emplSalDep, cmap='Spectral_r', ) #, vmin=1, vmax=2000)

"""###7 Гипотеза КПД"""

#7 Проверить гипотезу, что сотрудники с высоким окладом проводят на работе больше времени, чем сотрудники с низким окладом

emplSalLvl = df[['salary' , 'average_montly_hours']].groupby(['salary']).mean().fillna(0)
emplSalLvl = emplSalLvl.drop('medium')

print('Среднее время работы от уровня ЗП:\n', round(emplSalLvl, 2), '\n Корреляция:\n', emplSalLvl.corr())

emplSalLvl.plot(kind='pie', x='salary', y='average_montly_hours', subplots=True, autopct='%1.1f%%')

print('\nВывод: Уровень ЗП не влияет на КПД сотрудников\n')

"""###8 Расчеты по сотр"""

#8 Рассчитать следующие показатели среди уволившихся и неуволившихся сотрудников (по отдельности):

#разбиваем на работающих/уволенных
emplWork = df[df['left'] == 0]
emplLeft = df[df['left'] == 1]


##8.1 Доля сотрудников с повышением за последние 5 лет
#получаем общее кол-во работающих/уволенных кто повышался
emplALL =  df[['department','promotion_last_5years']].groupby('promotion_last_5years').count()
emplALL.rename(columns={'department':'all_workers'}, inplace=True)

#считаем повышения по работающим/уволенным
emplWorkProm5Y = emplWork[['department','promotion_last_5years']].groupby('promotion_last_5years').count()
emplLeftProm5Y = emplLeft[['department','promotion_last_5years']].groupby('promotion_last_5years').count()

#ренейм агрегатов
emplWorkProm5Y.rename(columns={'department':'worked'}, inplace=True)
emplLeftProm5Y.rename(columns={'department':'left'}, inplace=True)

#объединяем в общий DF все расчеты
unionDF = emplWorkProm5Y.merge(emplLeftProm5Y, how='inner', on='promotion_last_5years')
unionDF = unionDF.merge(emplALL, how='left', on='promotion_last_5years')

unionDF = unionDF.rename(index={0:'NO', 1:'YES'})

#считаем доли
unionDF['%_worked'] = round((unionDF['worked']/unionDF['all_workers'])*100 , 2)
unionDF['%_left'] = round((unionDF['left']/unionDF['all_workers'])*100 , 2)


print('Повышенные за 5 лет сотрудники (среди работающих/уволенных):\n', unionDF.iloc[:, [2, 0, 3, 1, 4]])

##8.2 Средняя степень удовлетворенности

#получаем общее кол-во работающих/уволенных по уровню удовлетворения
emplALL2 =  df[['left','satisfaction_level']].groupby('left').count()

#считаем средн. удовл. от работы по работающим/уволенным
emplSatLVLAVG = round(df[['left','satisfaction_level']].groupby('left').mean() , 2)

#ренейм агрегатов
emplALL2.rename(columns={'satisfaction_level':'all_workers'}, inplace=True)
emplSatLVLAVG.rename(columns={'satisfaction_level':'AVG_sat_level'}, inplace=True)

#объединяем в общий DF все расчеты
unionDF2 = emplSatLVLAVG.merge(emplALL2, how='inner', on='left')
unionDF2 = unionDF2.rename(index={0:'NO', 1:'YES'})

print('Средняя степень удовлетворенности среди работающих/уволенных сотрудников:\n', unionDF2)

##8.3 Среднее количество проектов

#получаем общее кол-во работающих/уволенных по кол-ву проектов
emplALL3 =  df[['left','number_project']].groupby('left').count()

#считаем средн. кол-во проектов по работающим/уволенным
emplProjsAVG = round(df[['left','number_project']].groupby('left').mean() , 2)

#ренейм агрегатов
emplALL3.rename(columns={'number_project':'all_workers'}, inplace=True)
emplProjsAVG.rename(columns={'number_project':'AVG_Projects'}, inplace=True)

#объединяем в общий DF все расчеты
unionDF3 = emplProjsAVG.merge(emplALL2, how='inner', on='left')
unionDF3 = unionDF3.rename(index={0:'NO', 1:'YES'})

print('Среднее кол-во проектов среди работающих/уволенных сотрудников:\n', unionDF3)

"""###9 LDA увольнений"""

#9 Разделить данные на тестовую и обучающую выборки
#Построить модель LDA, предсказывающую уволился ли сотрудник на основе имеющихся факторов (кроме department и salary)
#Оценить качество модели на тестовой выборки
import matplotlib.pyplot as plt
from matplotlib import colors

dfLDA = df

dfLDA = dfLDA.drop(['department','salary'], axis=1) #удаляем лишние столбцы

#dfLDATest = dfLDA['satisfaction_level']#[dfLDA['left'] == 1] #satisfaction_level , number_project , -- promotion_last_5years, average_monthly_hours​
#dfLDALearn = dfLDA['time_spend_company']#[dfLDA['left'] == 0] #last_evaluation
#dfLDALearn = dfLDALearn[3571:7142]#np.random.randn(3571), columns=[dfLDALearn.columns()]]

print(dfLDATest.head(), dfLDALearn.head())

#Разделяем данные
from sklearn.model_selection import train_test_split

#генерим тестовые данные
dfLDAT = np.array(np.random.randint(-100, 100, 14999))
print(dfLDAT, sum(dfLDAT)) #reshape(-1,1)

X_train, X_test, y_train, y_test = train_test_split(dfLDA, dfLDAT, test_size=0.25)

#print(X_train.values, y_train.values)
#print(X_train.values.reshape(-1, 1), y_train.values.reshape(-1, 1))

#обучаем lda 
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

lda = LinearDiscriminantAnalysis()

#X_train = X_train.values.reshape(-1, 1)
#y_train = y_train[0:11249].reshape(-1, 1)

#lda.fit(X_train.astype('float'), y_train.astype('int'))
#lda.fit(X_train, y_train.astype('int'))
lda.fit(X_train, y_train)

# делаем прогноз на тестовой выборке
#X_test = X_test.values.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

#print('predict(X_test)\n')
lda.predict(X_test)
#print('predict(y_test)\n')
#lda.predict(y_test)

# смотрим разницу факта и прогноза
#difFP = pd.DataFrame([lda.predict(y_test), lda.predict(X_test)]).T
difFP = pd.DataFrame([y_test, lda.predict(X_test[:1])]).T
difFP

# Визуализируем предсказания для тестовой выборки и центры классов
#satisfaction_level,last_evaluation,number_project,average_montly_hours,time_spend_company,Work_accident,left,promotion_last_5years

plt.scatter(x=X_train['average_montly_hours'], y=X_train['last_evaluation'], c=y_train, s=5) #,cmap ='inferno_r') satisfaction_level - average_montly_hours
plt.show()

small_train = X_train[(y_train == 0) | (y_train == 2)]
small_train = small_train[['average_montly_hours', 'last_evaluation']]
sy_train = y_train[(y_train == 0) | (y_train == 2)]
small_test = X_test[(y_test == 0) | (y_test == 2)]
small_test = small_test[['average_montly_hours', 'last_evaluation']]
sy_test = y_test[(y_test == 0) | (y_test == 2)]

plt.scatter(small_train['average_montly_hours'], small_train['last_evaluation'], c=sy_train)
plt.show()

#получаем центроиды
lda_small = LinearDiscriminantAnalysis()
lda_small.fit(small_train, sy_train)

lda_small.means_

# сам scatter plot
plt.scatter(small_train['average_montly_hours'], small_train['last_evaluation'], c=sy_train)
# центроиды
plt.scatter(lda_small.means_[:, 0], lda_small.means_[:, 1], c='r', s=100, marker='*')

# делаем условную "сетку"
nx, ny = 200, 100
x_min, x_max = plt.xlim()
y_min, y_max = plt.ylim()
xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),
                         np.linspace(y_min, y_max, ny))

# предсказываем класс каждой точки нашей сетки
Z = lda_small.predict_proba(np.c_[xx.ravel(), yy.ravel()])
Z = Z[:, 1].reshape(xx.shape)

# закрашиваем классы разными цветами
plt.pcolormesh(xx, yy, Z, #cmap='gist_earth_r',
                   norm=colors.Normalize(0., 1.), zorder=-1, shading='auto')

plt.contour(xx, yy, Z, [0.5], linewidths=2., colors='white')

"""### 10 GITHUB LINK"""

#10 Загрузить jupyter notebook с решение на github и прислать ссылку